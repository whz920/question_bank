{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://img.kaikeba.com/web/kkb_index/img_index_logo.png)\n",
    "# 基础课第一部分（python）第七次作业\n",
    "\n",
    "各位同学大家好！今天课上演示爬虫的原理，我们来回顾一下爬虫的思路，进行爬虫练习。\n",
    "爬虫是一个程序，这个程序可以获得网页数据。\n",
    "## 爬虫的思路\n",
    "- 1.首先确定需要爬取的网URL地址   \n",
    "[空气质量指数(http://www.tianqihoubao.com/aqi/)](http://www.tianqihoubao.com/aqi/)    \n",
    "\n",
    "\n",
    "- 2.通过HTTP/HTTPS协议来获取对应的HTML页面  \n",
    "\n",
    "\n",
    "- 3.提取HTML页面内有用的数据：\n",
    "- a. 如果是需要的数据--保存\n",
    "- b. 如果有其他URL，继续执行第二步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬虫练习 \n",
    "爬虫项目整体代码：  \n",
    "[高民权_中国城市空气质量数据抓取_Github](https://github.com/fortyMiles/ChineseAirConditionCrawler)  \n",
    "【没有头绪的指令】Github中的`get_location_info.py`文件对应city_coding的生成  \n",
    "\n",
    "**处理城市编码**  \n",
    "将`<div class=\"citychk\">`copy下来，进一步处理，生成 city_coding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请大家尽量尝试自己从网页中搜寻并copy，而不是直接从课件copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**首先安装包**  \n",
    "\n",
    "``` bash\n",
    "pip install bs4\n",
    "```\n",
    "参考：[Beautiful Soup 4.2.0 文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html)\n",
    "\n",
    "** 读取city_coding **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_coding(file='./city_coding'):\n",
    "    #your code\n",
    "city_coding = get_city_coding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 指定城市的URL地址确定 **\n",
    "- 如何拼接成自己想要的URL地址？  \n",
    "  如果是当前月份可以看到直接使用城市名称即可，如 http://www.tianqihoubao.com/aqi/hangzhou.html  \n",
    "  如果查询的是历史月份，可以看到是这种格式 http://www.tianqihoubao.com/aqi/hangzhou-201702.html   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url(city_coding, year=None, month=None):#输入城市 年 月 输出 url地址"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** HTTP 请求状态了解 **\n",
    "- 200 - 请求成功\n",
    "- 404 - 请求的资源（网页等）不存在\n",
    "- 403 - 服务器理解请求客户端的请求，但是拒绝执行此请求     \n",
    "\n",
    "** 模拟浏览器发送http请求 **\n",
    "- get post\n",
    "\n",
    "** 获得响应的数据 分析 保存**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(url, city_name):\n",
    "    # your code\n",
    "    pass\n",
    "\n",
    "def save_csv(file, data):\n",
    "    # your code \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 整体流程 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawler_all():\n",
    "    file = './data/allcity_2019.csv'\n",
    "    \n",
    "    city_codings = get_city_coding()\n",
    "    allcities = list(city_codings.keys())\n",
    "    \n",
    "    for city in allcities:\n",
    "        city_code = city_codings[city]\n",
    "        for year in range(2019,2012,-1):\n",
    "            for month in range(1,13):\n",
    "                url = build_url(city_code, year, month)\n",
    "                result = parse(url, city_code) # city\n",
    "                print(f'\\r{city} {year}-{month} {len(result)}', end='')\n",
    "                save_csv(file, result)\n",
    "                time.sleep(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    crawler_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
